{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "006c7353",
   "metadata": {},
   "source": [
    "# 03｜Step 2（模型）：值得佈陣打者（落點集中性）分類模型 + 模型比較\n",
    "\n",
    "本 Notebook 建立打者層級分類模型，用行為與情境化特徵預測「是否屬於落點高度集中（值得佈陣）」。\n",
    "\n",
    "模型：Logistic Regression（可解釋基準） vs Random Forest / XGBoost（非線性驗證）\n",
    "\n",
    "輸出：\n",
    "- `step2_model_comparison_metrics.csv`\n",
    "- `step2_model_comparison_test_predictions.csv`\n",
    "\n",
    "⚠️ 請先跑 Notebook 01，確保打者層級特徵檔存在（程式內會讀取）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e58964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#（Colab 可選）掛載 Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bb7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Step 2（學術版 / 乾淨無洩漏版）\n",
    "# 目的：用「打者行為特徵」預測打者是否屬於「落點高度集中（適合佈陣）」族群\n",
    "#\n",
    "# 三個修正（你要求的）：\n",
    "# (1) y 更嚴格：用 top3_share 的分位數（預設 top 25%）定義 y=1\n",
    "# (2) 防止標籤洩漏：X 不包含任何用來定義 y 的落點集中指標（top1/top3/entropy 一律不放）\n",
    "# (3) 任務定義更像論文：辨識「極端集中」打者（hard classification），不是「大多數都是1」\n",
    "#\n",
    "# 你會得到：\n",
    "# - step2_clean_batter_model_dataset.csv（含 y、閾值、特徵）\n",
    "# - step2_clean_logit_coefficients.csv（係數表）\n",
    "# - step2_clean_test_predictions.csv（測試集預測，用於挑 case study）\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ========= 0) 路徑設定（改這裡） =========\n",
    "DATA_DIR = \"/content/drive/MyDrive/CPBL_csv_tables_UTF8_BOM\"  # <- 改成你的資料夾\n",
    "PA_PATH   = os.path.join(DATA_DIR, \"PA.csv\")\n",
    "FEAR_PATH = os.path.join(DATA_DIR, \"batter_ctx_fear_pitch_gb_topzones_full.csv\")  # 有就用，沒有就跳過\n",
    "\n",
    "OUT_DATA = os.path.join(DATA_DIR, \"step2_clean_batter_model_dataset.csv\")\n",
    "OUT_COEF = os.path.join(DATA_DIR, \"step2_clean_logit_coefficients.csv\")\n",
    "OUT_PRED = os.path.join(DATA_DIR, \"step2_clean_test_predictions.csv\")\n",
    "\n",
    "# ========= 1) 讀檔 =========\n",
    "pa = pd.read_csv(PA_PATH, encoding=\"utf-8-sig\", low_memory=False)\n",
    "\n",
    "need = [\"batterName\", \"trajectory\", \"locationCode\", \"bases\"]\n",
    "for c in need:\n",
    "    if c not in pa.columns:\n",
    "        raise ValueError(f\"PA.csv missing required column: {c}\")\n",
    "\n",
    "pa[\"batterName\"] = pa[\"batterName\"].astype(str).str.strip()\n",
    "pa[\"trajectory\"] = pa[\"trajectory\"].astype(str).str.strip().str.upper()\n",
    "pa[\"locationCode_int\"] = pd.to_numeric(pa[\"locationCode\"], errors=\"coerce\")\n",
    "\n",
    "# ========= 2) 壘況分組（bases_group） =========\n",
    "def bases_group(b):\n",
    "    if b is None or (isinstance(b, float) and np.isnan(b)):\n",
    "        return \"UNK\"\n",
    "    s = str(b).strip()\n",
    "    if s == \"\" or s.lower() == \"nan\":\n",
    "        return \"UNK\"\n",
    "    if s in {\"0\",\"---\",\"EMPTY\",\"NONE\",\"none\",\"None\"}:\n",
    "        return \"Empty\"\n",
    "    u = s.upper()\n",
    "    # 很保守：只要字串帶有 2 / 3（或 2B/3B）就視作得點圈\n",
    "    if (\"2\" in s) or (\"3\" in s) or (\"2B\" in u) or (\"3B\" in u):\n",
    "        return \"RISP\"\n",
    "    return \"OnBase\"\n",
    "\n",
    "pa[\"bases_group\"] = pa[\"bases\"].apply(bases_group)\n",
    "\n",
    "# ========= 3) 取 GB 且有落點 =========\n",
    "is_gb = pa[\"trajectory\"].fillna(\"\").str.startswith(\"G\")\n",
    "gb = pa[is_gb & pa[\"locationCode_int\"].notna()].copy()\n",
    "\n",
    "# ========= 4) 落點方向（只用來做 X 的方向比例，不用來做 y） =========\n",
    "LEFT_ZONES   = {5, 45, 6, 56, 7}\n",
    "CENTER_ZONES = {1, 2, 12, 23, 4, 34}\n",
    "RIGHT_ZONES  = {3, 13, 14, 24, 8, 9}\n",
    "\n",
    "def zone_dir(z):\n",
    "    try:\n",
    "        z = int(z)\n",
    "    except:\n",
    "        return \"UNK\"\n",
    "    if z in LEFT_ZONES: return \"L\"\n",
    "    if z in CENTER_ZONES: return \"C\"\n",
    "    if z in RIGHT_ZONES: return \"R\"\n",
    "    return \"O\"\n",
    "\n",
    "gb[\"dir\"] = gb[\"locationCode_int\"].apply(zone_dir)\n",
    "\n",
    "# ========= 5) 先做 batter-level 基礎統計 =========\n",
    "MIN_PA = 100\n",
    "MIN_GB = 30  # 避免小樣本落點集中度不穩\n",
    "\n",
    "b_pa = pa.groupby(\"batterName\").size().rename(\"PA\").reset_index()\n",
    "b_gb = gb.groupby(\"batterName\").size().rename(\"GB_inplay_n\").reset_index()\n",
    "\n",
    "df = b_pa.merge(b_gb, on=\"batterName\", how=\"left\")\n",
    "df[\"GB_inplay_n\"] = df[\"GB_inplay_n\"].fillna(0).astype(int)\n",
    "df[\"GB_rate\"] = np.where(df[\"PA\"]>0, df[\"GB_inplay_n\"]/df[\"PA\"], np.nan)\n",
    "\n",
    "# 方向比例特徵（X）\n",
    "dir_pivot = (gb.pivot_table(index=\"batterName\", columns=\"dir\", values=\"locationCode_int\",\n",
    "                            aggfunc=\"count\", fill_value=0))\n",
    "for col in [\"L\",\"C\",\"R\",\"O\",\"UNK\"]:\n",
    "    if col not in dir_pivot.columns:\n",
    "        dir_pivot[col] = 0\n",
    "dir_pivot = dir_pivot[[\"L\",\"C\",\"R\",\"O\",\"UNK\"]].copy()\n",
    "dir_pivot[\"dir_total\"] = dir_pivot.sum(axis=1)\n",
    "\n",
    "for col in [\"L\",\"C\",\"R\"]:\n",
    "    dir_pivot[f\"dir_{col}_share\"] = np.where(dir_pivot[\"dir_total\"]>0, dir_pivot[col]/dir_pivot[\"dir_total\"], np.nan)\n",
    "\n",
    "dir_feat = dir_pivot.reset_index()[[\"batterName\",\"dir_L_share\",\"dir_C_share\",\"dir_R_share\"]]\n",
    "df = df.merge(dir_feat, on=\"batterName\", how=\"left\")\n",
    "\n",
    "# 情境穩定性特徵（X）：RISP 下 GB%（不是落點集中度）\n",
    "gb_risp = gb[gb[\"bases_group\"]==\"RISP\"].copy()\n",
    "risp_gb_n = gb_risp.groupby(\"batterName\").size().rename(\"GB_RISP_n\").reset_index()\n",
    "df = df.merge(risp_gb_n, on=\"batterName\", how=\"left\")\n",
    "df[\"GB_RISP_n\"] = df[\"GB_RISP_n\"].fillna(0).astype(int)\n",
    "df[\"GB_RISP_rate\"] = np.where(df[\"GB_inplay_n\"]>0, df[\"GB_RISP_n\"]/df[\"GB_inplay_n\"], np.nan)\n",
    "\n",
    "# ========= 6) （只用於定義 y）計算 top3_share =========\n",
    "# 注意：top3_share 只用於 y 的定義，後面不會放進 X\n",
    "TOPK = 3\n",
    "def topk_share(series, k=3):\n",
    "    vc = series.value_counts()\n",
    "    if vc.sum() == 0:\n",
    "        return np.nan\n",
    "    return vc.head(k).sum() / vc.sum()\n",
    "\n",
    "top3 = (gb.groupby(\"batterName\")[\"locationCode_int\"]\n",
    "          .apply(lambda s: topk_share(s, TOPK))\n",
    "          .rename(\"top3_share_for_label\")\n",
    "          .reset_index())\n",
    "\n",
    "df = df.merge(top3, on=\"batterName\", how=\"left\")\n",
    "\n",
    "# ========= 7) 建模母體（先過濾樣本量） =========\n",
    "model_df = df[(df[\"PA\"]>=MIN_PA) & (df[\"GB_inplay_n\"]>=MIN_GB) & df[\"top3_share_for_label\"].notna()].copy()\n",
    "\n",
    "# ========= 8) y：用分位數定義「極端集中」打者 =========\n",
    "# 例：TOP_Q = 0.75 -> top 25% 為 y=1\n",
    "TOP_Q = 0.75\n",
    "theta = float(model_df[\"top3_share_for_label\"].quantile(TOP_Q))\n",
    "model_df[\"y_shiftable\"] = (model_df[\"top3_share_for_label\"] >= theta).astype(int)\n",
    "\n",
    "print(\"建模打者數:\", len(model_df))\n",
    "print(\"使用分位數 TOP_Q =\", TOP_Q, \"=> theta =\", round(theta, 3))\n",
    "print(\"y=1 比例:\", round(model_df[\"y_shiftable\"].mean(), 3))\n",
    "\n",
    "# ========= 9) X：只用「行為特徵」，不含落點集中度 =========\n",
    "feature_cols = [\n",
    "    \"PA\", \"GB_inplay_n\", \"GB_rate\",\n",
    "    \"dir_L_share\", \"dir_C_share\", \"dir_R_share\",\n",
    "    \"GB_RISP_rate\", \"GB_RISP_n\",\n",
    "]\n",
    "\n",
    "# 加入 fear 特徵（如果存在）—這是行為特徵，不是落點集中度\n",
    "if os.path.exists(FEAR_PATH):\n",
    "    fear = pd.read_csv(FEAR_PATH, encoding=\"utf-8-sig\", low_memory=False)\n",
    "    fear[\"batterName\"] = fear[\"batterName\"].astype(str).str.strip()\n",
    "    if \"fear_whiff_rate\" in fear.columns:\n",
    "        fear_all = fear.groupby(\"batterName\")[\"fear_whiff_rate\"].mean().rename(\"fear_whiff_mean\").reset_index()\n",
    "        fear_risp = (fear[fear[\"bases_group\"]==\"RISP\"]\n",
    "                     .groupby(\"batterName\")[\"fear_whiff_rate\"]\n",
    "                     .mean()\n",
    "                     .rename(\"fear_whiff_RISP_mean\")\n",
    "                     .reset_index())\n",
    "        model_df = model_df.merge(fear_all, on=\"batterName\", how=\"left\").merge(fear_risp, on=\"batterName\", how=\"left\")\n",
    "        feature_cols += [\"fear_whiff_mean\", \"fear_whiff_RISP_mean\"]\n",
    "    else:\n",
    "        print(\"FEAR 表沒有 fear_whiff_rate，略過 fear 特徵\")\n",
    "else:\n",
    "    print(\"找不到 FEAR_PATH，略過 fear 特徵\")\n",
    "\n",
    "X = model_df[feature_cols].copy()\n",
    "y = model_df[\"y_shiftable\"].copy()\n",
    "\n",
    "# ========= 10) 以「打者」為單位切 train/test =========\n",
    "train_idx, test_idx = train_test_split(\n",
    "    model_df.index,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_test = X.loc[train_idx], X.loc[test_idx]\n",
    "y_train, y_test = y.loc[train_idx], y.loc[test_idx]\n",
    "\n",
    "# ========= 11) Logistic Regression pipeline =========\n",
    "pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=3000, class_weight=\"balanced\", solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "proba = pipe.predict_proba(X_test)[:, 1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "f1  = f1_score(y_test, pred)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"\\n=== Step 2（乾淨無洩漏版）Logistic Regression ===\")\n",
    "print(\"ROC-AUC:\", round(auc, 3))\n",
    "print(\"Accuracy:\", round(acc, 3))\n",
    "print(\"F1:\", round(f1, 3))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "print(\"\\nReport:\\n\", classification_report(y_test, pred, digits=3))\n",
    "\n",
    "# ========= 12) 係數表（可寫論文：標準化後係數可比） =========\n",
    "coef = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"Feature\": feature_cols, \"Coefficient\": coef}).sort_values(\"Coefficient\", ascending=False)\n",
    "coef_df.to_csv(OUT_COEF, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved coefficients:\", OUT_COEF)\n",
    "display(coef_df)\n",
    "\n",
    "# ========= 13) 輸出建模資料（含 theta 與 top3_share_for_label，但注意：這些不進 X） =========\n",
    "save_df = model_df.copy()\n",
    "save_df[\"label_theta\"] = theta\n",
    "save_df.to_csv(OUT_DATA, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved dataset:\", OUT_DATA)\n",
    "\n",
    "# ========= 14) 輸出測試集預測（挑 case study 超好用） =========\n",
    "result = save_df.loc[test_idx, [\"batterName\",\"PA\",\"GB_inplay_n\",\"GB_rate\",\"top3_share_for_label\",\"y_shiftable\"]].copy()\n",
    "result[\"pred_proba\"] = proba\n",
    "result[\"pred_label\"] = pred\n",
    "result = result.sort_values(\"pred_proba\", ascending=False)\n",
    "\n",
    "result.to_csv(OUT_PRED, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved test predictions:\", OUT_PRED)\n",
    "display(result.head(25))\n",
    "\n",
    "# ========= 15) （可選）快速 sanity check：看看 y=1 的 top3_share 分布是否真的較高 =========\n",
    "print(\"\\nLabel sanity check:\")\n",
    "print(\"top3_share median | y=0:\", round(save_df.loc[save_df.y_shiftable==0, \"top3_share_for_label\"].median(), 3))\n",
    "print(\"top3_share median | y=1:\", round(save_df.loc[save_df.y_shiftable==1, \"top3_share_for_label\"].median(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60407369",
   "metadata": {},
   "source": [
    "## 3.2 模型比較（Logistic vs RF vs XGBoost）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77485b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 2 三模型比較（Logit + RandomForest + XGBoost）\n",
    "# - 公平比較：同一份資料、同一個 y、同一個 train/test split\n",
    "# - 指標：ROC-AUC、PR-AUC、F1、Accuracy\n",
    "# - 輸出：comparison_metrics.csv、test_predictions.csv、\n",
    "#         logit_coefficients.csv、rf_importance.csv、xgb_importance.csv\n",
    "#\n",
    "# 你只要改：DATA_DIR 位置\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, f1_score, accuracy_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# ---- XGBoost（Colab 通常可用；沒有就安裝）----\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except Exception:\n",
    "    !pip -q install xgboost\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "# ======================\n",
    "# 0) 路徑設定（改這裡）\n",
    "# ======================\n",
    "DATA_DIR = \"/content/drive/MyDrive/CPBL_csv_tables_UTF8_BOM\"  # <- 改成你的資料夾\n",
    "DATA_PATH = os.path.join(DATA_DIR, \"step2_clean_batter_model_dataset.csv\")  # Step2 乾淨版資料\n",
    "OUT_METRICS = os.path.join(DATA_DIR, \"step2_model_comparison_metrics.csv\")\n",
    "OUT_PRED    = os.path.join(DATA_DIR, \"step2_model_comparison_test_predictions.csv\")\n",
    "OUT_LOGIT_COEF = os.path.join(DATA_DIR, \"step2_logit_coefficients.csv\")\n",
    "OUT_RF_IMP     = os.path.join(DATA_DIR, \"step2_rf_feature_importance.csv\")\n",
    "OUT_XGB_IMP    = os.path.join(DATA_DIR, \"step2_xgb_feature_importance.csv\")\n",
    "\n",
    "# ======================\n",
    "# 1) 讀取資料\n",
    "# ======================\n",
    "df = pd.read_csv(DATA_PATH, encoding=\"utf-8-sig\", low_memory=False)\n",
    "\n",
    "if \"y_shiftable\" not in df.columns:\n",
    "    raise ValueError(\"Dataset missing y_shiftable. 請確認你用的是 step2_clean_batter_model_dataset.csv\")\n",
    "\n",
    "# 你當初 Step2 用到的 feature_cols（若你有加新特徵，請在下面補進去）\n",
    "# 注意：不要把 top3_share_for_label / label_theta / pred_proba 類的放進來\n",
    "DEFAULT_FEATURE_COLS = [\n",
    "    \"PA\", \"GB_inplay_n\", \"GB_rate\",\n",
    "    \"dir_L_share\", \"dir_C_share\", \"dir_R_share\",\n",
    "    \"GB_RISP_rate\", \"GB_RISP_n\",\n",
    "    \"fear_whiff_mean\", \"fear_whiff_RISP_mean\"\n",
    "]\n",
    "feature_cols = [c for c in DEFAULT_FEATURE_COLS if c in df.columns]\n",
    "\n",
    "if len(feature_cols) < 4:\n",
    "    raise ValueError(f\"可用特徵太少：{feature_cols}。請確認資料欄位，或把你的特徵欄位名補進 DEFAULT_FEATURE_COLS\")\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"y_shiftable\"].astype(int).copy()\n",
    "\n",
    "print(\"建模打者數:\", len(df))\n",
    "print(\"y=1 比例:\", round(y.mean(), 3))\n",
    "print(\"使用特徵:\", feature_cols)\n",
    "\n",
    "# ======================\n",
    "# 2) 固定切分（公平比較）\n",
    "# ======================\n",
    "train_idx, test_idx = train_test_split(\n",
    "    df.index, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_test = X.loc[train_idx], X.loc[test_idx]\n",
    "y_train, y_test = y.loc[train_idx], y.loc[test_idx]\n",
    "\n",
    "print(\"Train size:\", len(train_idx), \"Test size:\", len(test_idx))\n",
    "print(\"Train y=1:\", round(y_train.mean(), 3), \"Test y=1:\", round(y_test.mean(), 3))\n",
    "\n",
    "# ======================\n",
    "# 3) 建立三個模型（同樣 imputer；Logit 需要 scaler）\n",
    "# ======================\n",
    "logit = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=5000, class_weight=\"balanced\", solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "rf = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=800,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        min_samples_leaf=2\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 針對小樣本：XGB 不要太深，避免 overfit\n",
    "pos = (y_train == 1).sum()\n",
    "neg = (y_train == 0).sum()\n",
    "scale_pos_weight = (neg / max(pos, 1))\n",
    "\n",
    "xgb = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"clf\", XGBClassifier(\n",
    "        n_estimators=600,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\",\n",
    "        scale_pos_weight=scale_pos_weight\n",
    "    ))\n",
    "])\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": logit,\n",
    "    \"RandomForest\": rf,\n",
    "    \"XGBoost\": xgb\n",
    "}\n",
    "\n",
    "# ======================\n",
    "# 4) 評估函數\n",
    "# ======================\n",
    "def eval_model(name, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    pr  = average_precision_score(y_test, proba)  # PR-AUC\n",
    "    f1  = f1_score(y_test, pred)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "\n",
    "    print(\"\\n====\", name, \"====\")\n",
    "    print(\"ROC-AUC:\", round(auc, 3))\n",
    "    print(\"PR-AUC :\", round(pr, 3))\n",
    "    print(\"Acc   :\", round(acc, 3))\n",
    "    print(\"F1    :\", round(f1, 3))\n",
    "    print(\"Confusion:\\n\", confusion_matrix(y_test, pred))\n",
    "    print(classification_report(y_test, pred, digits=3))\n",
    "\n",
    "    return auc, pr, acc, f1, proba, pred\n",
    "\n",
    "rows = []\n",
    "pred_pack = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    auc, pr, acc, f1, proba, pred = eval_model(name, model)\n",
    "    rows.append({\"Model\": name, \"ROC_AUC\": auc, \"PR_AUC\": pr, \"Accuracy\": acc, \"F1\": f1})\n",
    "    pred_pack.append((name, proba, pred))\n",
    "\n",
    "metrics_df = pd.DataFrame(rows).sort_values(\"ROC_AUC\", ascending=False)\n",
    "metrics_df.to_csv(OUT_METRICS, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"\\nSaved metrics ->\", OUT_METRICS)\n",
    "display(metrics_df)\n",
    "\n",
    "# ======================\n",
    "# 5) 輸出 test 預測（挑 case study 用）\n",
    "# ======================\n",
    "base_cols = [\"batterName\", \"PA\", \"GB_inplay_n\", \"GB_rate\", \"top3_share_for_label\", \"y_shiftable\"]\n",
    "base_cols = [c for c in base_cols if c in df.columns]\n",
    "\n",
    "pred_df = df.loc[test_idx, base_cols].copy() if base_cols else df.loc[test_idx, [\"y_shiftable\"]].copy()\n",
    "for name, proba, pred in pred_pack:\n",
    "    pred_df[f\"{name}_proba\"] = proba\n",
    "    pred_df[f\"{name}_pred\"] = pred\n",
    "\n",
    "pred_df = pred_df.sort_values([c for c in pred_df.columns if c.endswith(\"_proba\")][0], ascending=False)\n",
    "pred_df.to_csv(OUT_PRED, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved test predictions ->\", OUT_PRED)\n",
    "display(pred_df.head(25))\n",
    "\n",
    "# ======================\n",
    "# 6) 特徵解釋輸出（Logit 係數 / RF & XGB 重要性）\n",
    "# ======================\n",
    "# ---- Logit 係數 ----\n",
    "logit_fit = models[\"LogisticRegression\"].fit(X_train, y_train)\n",
    "coef = logit_fit.named_steps[\"clf\"].coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"Feature\": feature_cols, \"Coefficient\": coef}).sort_values(\"Coefficient\", ascending=False)\n",
    "coef_df.to_csv(OUT_LOGIT_COEF, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved logit coefficients ->\", OUT_LOGIT_COEF)\n",
    "display(coef_df)\n",
    "\n",
    "# ---- RF 重要性 ----\n",
    "rf_fit = models[\"RandomForest\"].fit(X_train, y_train)\n",
    "rf_imp = rf_fit.named_steps[\"clf\"].feature_importances_\n",
    "rf_imp_df = pd.DataFrame({\"Feature\": feature_cols, \"Importance\": rf_imp}).sort_values(\"Importance\", ascending=False)\n",
    "rf_imp_df.to_csv(OUT_RF_IMP, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved RF importances ->\", OUT_RF_IMP)\n",
    "display(rf_imp_df.head(15))\n",
    "\n",
    "# ---- XGB 重要性 ----\n",
    "xgb_fit = models[\"XGBoost\"].fit(X_train, y_train)\n",
    "xgb_imp = xgb_fit.named_steps[\"clf\"].feature_importances_\n",
    "xgb_imp_df = pd.DataFrame({\"Feature\": feature_cols, \"Importance\": xgb_imp}).sort_values(\"Importance\", ascending=False)\n",
    "xgb_imp_df.to_csv(OUT_XGB_IMP, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved XGB importances ->\", OUT_XGB_IMP)\n",
    "display(xgb_imp_df.head(15))\n",
    "\n",
    "# ======================\n",
    "# 7) （可選）交叉驗證 AUC：讓論文更像研究\n",
    "# ======================\n",
    "print(\"\\n=== 5-fold Stratified CV（ROC-AUC）===\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for name, model in models.items():\n",
    "    # 用 whole dataset 做 CV（仍然不含 label leakage 特徵）\n",
    "    aucs = cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\")\n",
    "    print(f\"{name:>18}  mean AUC={aucs.mean():.3f}  std={aucs.std():.3f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
